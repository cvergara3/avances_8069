# -*- coding: utf-8 -*-
"""Copia de main2D.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WbZpNQzNIssRiXZqsWPoV3dvrO2XytGZ
"""

!pip install sporco

!nvidia-smi

from google.colab import drive
drive.mount('/content/drive')

import sys
import os
import tensorflow as tf
from tensorflow.keras.layers import *

sys.path.append('/content/drive/My Drive/Proyecto_Minciencias/codigos')

# os.environ["CUDA_VISIBLE_DEVICES"] = "1"

gpus = tf.config.list_physical_devices('GPU')

if gpus:
    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
    try:
        tf.config.set_logical_device_configuration(
            gpus[0],
            [tf.config.LogicalDeviceConfiguration(memory_limit=8 * 1024)])
        logical_gpus = tf.config.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
        # Virtual devices must be set before GPUs have been initialized
        print(e)

from Unet2D import *
from Conv import *
from SensingModel2D import *
from metrics import *
from models2D import *
from sampling_schemes import *
from plots import *
from utils import *

path = os.path.join("..", "..", "Data")
path_results = os.path.join("..", "Results2D")
SR = 0.3
shot = 1

#######################
# SEISMIC PARAMETERES #
#######################

Data = np.load('/content/drive/My Drive/Proyecto_Minciencias/Data_train-20241226T125148Z-001/Data_train/patch_LL.npy')

# reshape
Data_resh = Data[np.newaxis,:,:,:]
Data_resh = np.transpose(Data_resh, (3,1,2,0))

# #random selection of data
# idx = np.random.permutation(Data.shape[2])
# idx_train = idx[0:int(Data.shape[2]*0.1)]
# idx_pred = idx[int(Data.shape[2]*0.1):int(Data.shape[2]*0.2)]
# idx_val = idx[int(Data.shape[2]*0.9):Data.shape[2]]

# order selection of data to force NN to remove some traces
t_shots = Data.shape[2]
idx = np.arange(t_shots)
idx_train = idx[0:int(t_shots*0.3)] # left hyperbola
idx_pred = idx[int(t_shots*0.3):int(t_shots*0.4)] # center hyperbola
idx_val = idx[int(t_shots*0.9):t_shots] # right hyperbola

# split of the data btw train, val and pred
DataTrain = normalize_data(Data_resh[idx_train,:,:,:])
DataPred = normalize_data(Data_resh[idx_pred,:,:,:])
DataVal = normalize_data(Data_resh[idx_val,:,:,:])

print('Data train size ' + str(DataTrain.shape))
print('Data test size ' + str(DataPred.shape))

# graphic test and train datasets
plot_dataset(DataTrain, DataPred, 1) # last entry is the shot number

# models summary
latent_dim = DataTrain.shape[1] #DataTrain.shape[1]
PROPOSED = True

recons_net = recons_network(DataTrain)

mask_model = sensing_model(latent_dim, trainable=PROPOSED)
model = build_model(recons_net, mask_model, DataTrain[0,:,:,:].shape)

# mask_model.save_weights(path_results + 'baseline.h5')

# if not PROPOSED:
#     mask_model.load_weights(path_results + 'baseline.h5')

# save initial PHI matrix
weights_init = binary_sigmoid_unit(mask_model.get_weights()[0]@mask_model.get_weights()[1]) # matrix product Az to get the weights
#weights_init = binary_sigmoid_unit(mask_model.get_weights()[0]) # save weights
print('removed traces: ' + str(tf.math.reduce_sum(weights_init)) +
f'\nsampling rate is: ' + str(tf.math.reduce_sum(weights_init)*100/DataTrain.shape[2]))

# plot initial mask
plot_mask(mask_model(DataTrain), 2) # entries are Data and shot

# model compilation
model.compile(optimizer=tf.optimizers.Adam(0.001), loss="mse", metrics=[get_psnr()])
model.summary(print_fn=myprint(model.summary))
recons_net.summary()

history = model.fit(x=DataTrain,
                    y=DataTrain,
                    batch_size=64,
                    epochs=500,
                    validation_data=(DataPred, DataPred),
                    callbacks = [reduce_lr(), mcp_save()])

# temp_save_results = os.path.join(path_results, 'weights_best.h5')
# model.load_weights(temp_save_results)

plot_loss(history.history['loss'][10:], history.history['val_loss'][10:])
# plot_loss_normalized(history.history['psnr'][10:], history.history['val_psnr'][10:], w=4)

# data test
corrupted = mask_model(DataPred)
estimated = recons_net(corrupted)

# save final PHI matrix
weights_out = binary_sigmoid_unit(mask_model.get_weights()[0]@mask_model.get_weights()[1])
#weights_out = binary_sigmoid_unit(mask_model.get_weights()[0])
print_SR(weights_out, DataTrain)

# graphic results
plot_results(DataPred, corrupted, estimated, shot)
# plot_mask(mask_model(normalize_data(DataPred)), shot=-1)
# plt.imshow(np.abs(estimated[50,:,:,0] - DataPred[50,:,:,0]), cmap='jet', vmax=0.2, vmin=0), plt.colorbar(), plt.show()

# calculate metrics
get_metrics(DataPred, estimated, weights_out)

######################
# comparison UNIFORM #
######################
corrupted_uniform = uniform_sampling(DataPred, SR)
estimated_uniform = recons_net(corrupted_uniform[0])

# save final PHI matrix
weights_out_uniform = binary_sigmoid_unit(np.array(np.reshape(corrupted_uniform[1],(1,128)),dtype=np.float32))
print_SR(weights_out_uniform, DataTrain)

# graphic results
plot_results(DataPred, corrupted_uniform[0], estimated_uniform, shot)
get_metrics(DataPred, estimated_uniform, weights_out_uniform)
# plt.imshow(estimated_uniform[-1,:,:,0] - DataPred[-1,:,:,0], cmap='jet', vmax=0.3, vmin=-0.3), plt.colorbar(), plt.show()

#####################
# comparison RANDOM #
#####################
corrupted_random = random_sampling(DataPred, SR)
estimated_random = recons_net(corrupted_random[0])

# save final PHI matrix
weights_out_random = binary_sigmoid_unit(np.array(np.reshape(corrupted_random[1],(1,128)),dtype=np.float32))
print_SR(weights_out_random, DataTrain)

# graphic results
plot_results(DataPred, corrupted_random[0], estimated_random, shot)
get_metrics(DataPred, estimated_random, weights_out_random)

#####################
# comparison JITTER #
#####################
corrupted_jitter = jitter_sampling(DataPred, SR, 8)
estimated_jitter = recons_net(corrupted_jitter[0])

# save final PHI matrix

weights_out_jitter = binary_sigmoid_unit(np.reshape(corrupted_jitter[1],(1,128)))
print_SR(weights_out_jitter, DataTrain)

# graphic results
plot_results(DataPred, corrupted_jitter[0], estimated_jitter, shot)
get_metrics(DataPred, estimated_jitter, weights_out_jitter)